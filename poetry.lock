[[package]]
name = "py4j"
version = "0.10.9.5"
description = "Enables Python programs to dynamically access arbitrary Java objects"
category = "main"
optional = false
python-versions = "*"

[[package]]
name = "pyspark"
version = "3.3.1"
description = "Apache Spark Python API"
category = "main"
optional = false
python-versions = ">=3.7"

[package.dependencies]
py4j = "0.10.9.5"

[package.extras]
ml = ["numpy (>=1.15)"]
mllib = ["numpy (>=1.15)"]
pandas_on_spark = ["numpy (>=1.15)", "pandas (>=1.0.5)", "pyarrow (>=1.0.0)"]
sql = ["pandas (>=1.0.5)", "pyarrow (>=1.0.0)"]

[metadata]
lock-version = "1.1"
python-versions = "^3.10"
content-hash = "9802babc8d5b39d309acfb025cc81d40b7e3a24d5b326e48f0648d70ee1e17d0"

[metadata.files]
py4j = []
pyspark = []
